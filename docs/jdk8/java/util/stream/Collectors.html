<html>
    <head>
        <link rel="stylesheet" type="text/css" href="/css/styles.css"/>
    </head>
<body>
<pre class="code">
/*
 * Copyright (c) 2012, 2013, Oracle and/or its affiliates. All rights reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 *
 * This code is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 only, as
 * published by the Free Software Foundation.  Oracle designates this
 * particular file as subject to the &quot;Classpath&quot; exception as provided
 * by Oracle in the LICENSE file that accompanied this code.
 *
 * This code is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 * version 2 for more details (a copy is included in the LICENSE file that
 * accompanied this code).
 *
 * You should have received a copy of the GNU General Public License version
 * 2 along with this work; if not, write to the Free Software Foundation,
 * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 *
 * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 * or visit www.oracle.com if you need additional information or have any
 * questions.
 */
package java.util.stream;

import java.util.AbstractMap;
import java.util.AbstractSet;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Comparator;
import java.util.DoubleSummaryStatistics;
import java.util.EnumSet;
import java.util.HashMap;
import java.util.HashSet;
import java.util.IntSummaryStatistics;
import java.util.Iterator;
import java.util.List;
import java.util.LongSummaryStatistics;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import java.util.Set;
import java.util.StringJoiner;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.ConcurrentMap;
import java.util.function.BiConsumer;
import java.util.function.BiFunction;
import java.util.function.BinaryOperator;
import java.util.function.Consumer;
import java.util.function.Function;
import java.util.function.Predicate;
import java.util.function.Supplier;
import java.util.function.ToDoubleFunction;
import java.util.function.ToIntFunction;
import java.util.function.ToLongFunction;

/**
 * Implementations of {@link Collector} that implement various useful reduction
 * operations, such as accumulating elements into collections, summarizing
 * elements according to various criteria, etc.
 *
 * &lt;p&gt;The following are examples of using the predefined collectors to perform
 * common mutable reduction tasks:
 *
 * &lt;pre&gt;{@code
 *     // Accumulate names into a List
 *     List&lt;String&gt; list = people.stream().map(Person::getName).collect(Collectors.toList());
 *
 *     // Accumulate names into a TreeSet
 *     Set&lt;String&gt; set = people.stream().map(Person::getName).collect(Collectors.toCollection(TreeSet::new));
 *
 *     // Convert elements to strings and concatenate them, separated by commas
 *     String joined = things.stream()
 *                           .map(Object::toString)
 *                           .collect(Collectors.joining(&quot;, &quot;));
 *
 *     // Compute sum of salaries of employee
 *     int total = employees.stream()
 *                          .collect(Collectors.summingInt(Employee::getSalary)));
 *
 *     // Group employees by department
 *     Map&lt;Department, List&lt;Employee&gt;&gt; byDept
 *         = employees.stream()
 *                    .collect(Collectors.groupingBy(Employee::getDepartment));
 *
 *     // Compute sum of salaries by department
 *     Map&lt;Department, Integer&gt; totalByDept
 *         = employees.stream()
 *                    .collect(Collectors.groupingBy(Employee::getDepartment,
 *                                                   Collectors.summingInt(Employee::getSalary)));
 *
 *     // Partition students into passing and failing
 *     Map&lt;Boolean, List&lt;Student&gt;&gt; passingFailing =
 *         students.stream()
 *                 .collect(Collectors.partitioningBy(s -&gt; s.getGrade() &gt;= PASS_THRESHOLD));
 *
 * }&lt;/pre&gt;
 *
 * @since 1.8
 */
public final class Collectors {

    static final Set&lt;Collector.Characteristics&gt; CH_CONCURRENT_ID
            = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.CONCURRENT,
                                                     Collector.Characteristics.UNORDERED,
                                                     Collector.Characteristics.IDENTITY_FINISH));
    static final Set&lt;Collector.Characteristics&gt; CH_CONCURRENT_NOID
            = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.CONCURRENT,
                                                     Collector.Characteristics.UNORDERED));
    static final Set&lt;Collector.Characteristics&gt; CH_ID
            = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.IDENTITY_FINISH));
    static final Set&lt;Collector.Characteristics&gt; CH_UNORDERED_ID
            = Collections.unmodifiableSet(EnumSet.of(Collector.Characteristics.UNORDERED,
                                                     Collector.Characteristics.IDENTITY_FINISH));
    static final Set&lt;Collector.Characteristics&gt; CH_NOID = Collections.emptySet();

    private Collectors() { }

    /**
     * Returns a merge function, suitable for use in
     * {@link Map#merge(Object, Object, BiFunction) Map.merge()} or
     * {@link #toMap(Function, Function, BinaryOperator) toMap()}, which always
     * throws {@code IllegalStateException}.  This can be used to enforce the
     * assumption that the elements being collected are distinct.
     *
     * @param &lt;T&gt; the type of input arguments to the merge function
     * @return a merge function which always throw {@code IllegalStateException}
     */
    private static &lt;T&gt; BinaryOperator&lt;T&gt; throwingMerger() {
        return (u,v) -&gt; { throw new IllegalStateException(String.format(&quot;Duplicate key %s&quot;, u)); };
    }

    @SuppressWarnings(&quot;unchecked&quot;)
    private static &lt;I, R&gt; Function&lt;I, R&gt; castingIdentity() {
        return i -&gt; (R) i;
    }

    /**
     * Simple implementation class for {@code Collector}.
     *
     * @param &lt;T&gt; the type of elements to be collected
     * @param &lt;R&gt; the type of the result
     */
    static class CollectorImpl&lt;T, A, R&gt; implements Collector&lt;T, A, R&gt; {
        private final Supplier&lt;A&gt; supplier;
        private final BiConsumer&lt;A, T&gt; accumulator;
        private final BinaryOperator&lt;A&gt; combiner;
        private final Function&lt;A, R&gt; finisher;
        private final Set&lt;Characteristics&gt; characteristics;

        CollectorImpl(Supplier&lt;A&gt; supplier,
                      BiConsumer&lt;A, T&gt; accumulator,
                      BinaryOperator&lt;A&gt; combiner,
                      Function&lt;A,R&gt; finisher,
                      Set&lt;Characteristics&gt; characteristics) {
            this.supplier = supplier;
            this.accumulator = accumulator;
            this.combiner = combiner;
            this.finisher = finisher;
            this.characteristics = characteristics;
        }

        CollectorImpl(Supplier&lt;A&gt; supplier,
                      BiConsumer&lt;A, T&gt; accumulator,
                      BinaryOperator&lt;A&gt; combiner,
                      Set&lt;Characteristics&gt; characteristics) {
            this(supplier, accumulator, combiner, castingIdentity(), characteristics);
        }

        @Override
        public BiConsumer&lt;A, T&gt; accumulator() {
            return accumulator;
        }

        @Override
        public Supplier&lt;A&gt; supplier() {
            return supplier;
        }

        @Override
        public BinaryOperator&lt;A&gt; combiner() {
            return combiner;
        }

        @Override
        public Function&lt;A, R&gt; finisher() {
            return finisher;
        }

        @Override
        public Set&lt;Characteristics&gt; characteristics() {
            return characteristics;
        }
    }

    /**
     * Returns a {@code Collector} that accumulates the input elements into a
     * new {@code Collection}, in encounter order.  The {@code Collection} is
     * created by the provided factory.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;C&gt; the type of the resulting {@code Collection}
     * @param collectionFactory a {@code Supplier} which returns a new, empty
     * {@code Collection} of the appropriate type
     * @return a {@code Collector} which collects all the input elements into a
     * {@code Collection}, in encounter order
     */
    public static &lt;T, C extends Collection&lt;T&gt;&gt;
    Collector&lt;T, ?, C&gt; toCollection(Supplier&lt;C&gt; collectionFactory) {
        return new CollectorImpl&lt;&gt;(collectionFactory, Collection&lt;T&gt;::add,
                                   (r1, r2) -&gt; { r1.addAll(r2); return r1; },
                                   CH_ID);
    }

    /**
     * Returns a {@code Collector} that accumulates the input elements into a
     * new {@code List}. There are no guarantees on the type, mutability,
     * serializability, or thread-safety of the {@code List} returned; if more
     * control over the returned {@code List} is required, use {@link #toCollection(Supplier)}.
     *
     * @param &lt;T&gt; the type of the input elements
     * @return a {@code Collector} which collects all the input elements into a
     * {@code List}, in encounter order
     */
    public static &lt;T&gt;
    Collector&lt;T, ?, List&lt;T&gt;&gt; toList() {
        return new CollectorImpl&lt;&gt;((Supplier&lt;List&lt;T&gt;&gt;) ArrayList::new, List::add,
                                   (left, right) -&gt; { left.addAll(right); return left; },
                                   CH_ID);
    }

    /**
     * Returns a {@code Collector} that accumulates the input elements into a
     * new {@code Set}. There are no guarantees on the type, mutability,
     * serializability, or thread-safety of the {@code Set} returned; if more
     * control over the returned {@code Set} is required, use
     * {@link #toCollection(Supplier)}.
     *
     * &lt;p&gt;This is an {@link Collector.Characteristics#UNORDERED unordered}
     * Collector.
     *
     * @param &lt;T&gt; the type of the input elements
     * @return a {@code Collector} which collects all the input elements into a
     * {@code Set}
     */
    public static &lt;T&gt;
    Collector&lt;T, ?, Set&lt;T&gt;&gt; toSet() {
        return new CollectorImpl&lt;&gt;((Supplier&lt;Set&lt;T&gt;&gt;) HashSet::new, Set::add,
                                   (left, right) -&gt; { left.addAll(right); return left; },
                                   CH_UNORDERED_ID);
    }

    /**
     * Returns a {@code Collector} that concatenates the input elements into a
     * {@code String}, in encounter order.
     *
     * @return a {@code Collector} that concatenates the input elements into a
     * {@code String}, in encounter order
     */
    public static Collector&lt;CharSequence, ?, String&gt; joining() {
        return new CollectorImpl&lt;CharSequence, StringBuilder, String&gt;(
                StringBuilder::new, StringBuilder::append,
                (r1, r2) -&gt; { r1.append(r2); return r1; },
                StringBuilder::toString, CH_NOID);
    }

    /**
     * Returns a {@code Collector} that concatenates the input elements,
     * separated by the specified delimiter, in encounter order.
     *
     * @param delimiter the delimiter to be used between each element
     * @return A {@code Collector} which concatenates CharSequence elements,
     * separated by the specified delimiter, in encounter order
     */
    public static Collector&lt;CharSequence, ?, String&gt; joining(CharSequence delimiter) {
        return joining(delimiter, &quot;&quot;, &quot;&quot;);
    }

    /**
     * Returns a {@code Collector} that concatenates the input elements,
     * separated by the specified delimiter, with the specified prefix and
     * suffix, in encounter order.
     *
     * @param delimiter the delimiter to be used between each element
     * @param  prefix the sequence of characters to be used at the beginning
     *                of the joined result
     * @param  suffix the sequence of characters to be used at the end
     *                of the joined result
     * @return A {@code Collector} which concatenates CharSequence elements,
     * separated by the specified delimiter, in encounter order
     */
    public static Collector&lt;CharSequence, ?, String&gt; joining(CharSequence delimiter,
                                                             CharSequence prefix,
                                                             CharSequence suffix) {
        return new CollectorImpl&lt;&gt;(
                () -&gt; new StringJoiner(delimiter, prefix, suffix),
                StringJoiner::add, StringJoiner::merge,
                StringJoiner::toString, CH_NOID);
    }

    /**
     * {@code BinaryOperator&lt;Map&gt;} that merges the contents of its right
     * argument into its left argument, using the provided merge function to
     * handle duplicate keys.
     *
     * @param &lt;K&gt; type of the map keys
     * @param &lt;V&gt; type of the map values
     * @param &lt;M&gt; type of the map
     * @param mergeFunction A merge function suitable for
     * {@link Map#merge(Object, Object, BiFunction) Map.merge()}
     * @return a merge function for two maps
     */
    private static &lt;K, V, M extends Map&lt;K,V&gt;&gt;
    BinaryOperator&lt;M&gt; mapMerger(BinaryOperator&lt;V&gt; mergeFunction) {
        return (m1, m2) -&gt; {
            for (Map.Entry&lt;K,V&gt; e : m2.entrySet())
                m1.merge(e.getKey(), e.getValue(), mergeFunction);
            return m1;
        };
    }

    /**
     * Adapts a {@code Collector} accepting elements of type {@code U} to one
     * accepting elements of type {@code T} by applying a mapping function to
     * each input element before accumulation.
     *
     * @apiNote
     * The {@code mapping()} collectors are most useful when used in a
     * multi-level reduction, such as downstream of a {@code groupingBy} or
     * {@code partitioningBy}.  For example, given a stream of
     * {@code Person}, to accumulate the set of last names in each city:
     * &lt;pre&gt;{@code
     *     Map&lt;City, Set&lt;String&gt;&gt; lastNamesByCity
     *         = people.stream().collect(groupingBy(Person::getCity,
     *                                              mapping(Person::getLastName, toSet())));
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;U&gt; type of elements accepted by downstream collector
     * @param &lt;A&gt; intermediate accumulation type of the downstream collector
     * @param &lt;R&gt; result type of collector
     * @param mapper a function to be applied to the input elements
     * @param downstream a collector which will accept mapped values
     * @return a collector which applies the mapping function to the input
     * elements and provides the mapped results to the downstream collector
     */
    public static &lt;T, U, A, R&gt;
    Collector&lt;T, ?, R&gt; mapping(Function&lt;? super T, ? extends U&gt; mapper,
                               Collector&lt;? super U, A, R&gt; downstream) {
        BiConsumer&lt;A, ? super U&gt; downstreamAccumulator = downstream.accumulator();
        return new CollectorImpl&lt;&gt;(downstream.supplier(),
                                   (r, t) -&gt; downstreamAccumulator.accept(r, mapper.apply(t)),
                                   downstream.combiner(), downstream.finisher(),
                                   downstream.characteristics());
    }

    /**
     * Adapts a {@code Collector} to perform an additional finishing
     * transformation.  For example, one could adapt the {@link #toList()}
     * collector to always produce an immutable list with:
     * &lt;pre&gt;{@code
     *     List&lt;String&gt; people
     *         = people.stream().collect(collectingAndThen(toList(), Collections::unmodifiableList));
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;A&gt; intermediate accumulation type of the downstream collector
     * @param &lt;R&gt; result type of the downstream collector
     * @param &lt;RR&gt; result type of the resulting collector
     * @param downstream a collector
     * @param finisher a function to be applied to the final result of the downstream collector
     * @return a collector which performs the action of the downstream collector,
     * followed by an additional finishing step
     */
    public static&lt;T,A,R,RR&gt; Collector&lt;T,A,RR&gt; collectingAndThen(Collector&lt;T,A,R&gt; downstream,
                                                                Function&lt;R,RR&gt; finisher) {
        Set&lt;Collector.Characteristics&gt; characteristics = downstream.characteristics();
        if (characteristics.contains(Collector.Characteristics.IDENTITY_FINISH)) {
            if (characteristics.size() == 1)
                characteristics = Collectors.CH_NOID;
            else {
                characteristics = EnumSet.copyOf(characteristics);
                characteristics.remove(Collector.Characteristics.IDENTITY_FINISH);
                characteristics = Collections.unmodifiableSet(characteristics);
            }
        }
        return new CollectorImpl&lt;&gt;(downstream.supplier(),
                                   downstream.accumulator(),
                                   downstream.combiner(),
                                   downstream.finisher().andThen(finisher),
                                   characteristics);
    }

    /**
     * Returns a {@code Collector} accepting elements of type {@code T} that
     * counts the number of input elements.  If no elements are present, the
     * result is 0.
     *
     * @implSpec
     * This produces a result equivalent to:
     * &lt;pre&gt;{@code
     *     reducing(0L, e -&gt; 1L, Long::sum)
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @return a {@code Collector} that counts the input elements
     */
    public static &lt;T&gt; Collector&lt;T, ?, Long&gt;
    counting() {
        return reducing(0L, e -&gt; 1L, Long::sum);
    }

    /**
     * Returns a {@code Collector} that produces the minimal element according
     * to a given {@code Comparator}, described as an {@code Optional&lt;T&gt;}.
     *
     * @implSpec
     * This produces a result equivalent to:
     * &lt;pre&gt;{@code
     *     reducing(BinaryOperator.minBy(comparator))
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @param comparator a {@code Comparator} for comparing elements
     * @return a {@code Collector} that produces the minimal value
     */
    public static &lt;T&gt; Collector&lt;T, ?, Optional&lt;T&gt;&gt;
    minBy(Comparator&lt;? super T&gt; comparator) {
        return reducing(BinaryOperator.minBy(comparator));
    }

    /**
     * Returns a {@code Collector} that produces the maximal element according
     * to a given {@code Comparator}, described as an {@code Optional&lt;T&gt;}.
     *
     * @implSpec
     * This produces a result equivalent to:
     * &lt;pre&gt;{@code
     *     reducing(BinaryOperator.maxBy(comparator))
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @param comparator a {@code Comparator} for comparing elements
     * @return a {@code Collector} that produces the maximal value
     */
    public static &lt;T&gt; Collector&lt;T, ?, Optional&lt;T&gt;&gt;
    maxBy(Comparator&lt;? super T&gt; comparator) {
        return reducing(BinaryOperator.maxBy(comparator));
    }

    /**
     * Returns a {@code Collector} that produces the sum of a integer-valued
     * function applied to the input elements.  If no elements are present,
     * the result is 0.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a function extracting the property to be summed
     * @return a {@code Collector} that produces the sum of a derived property
     */
    public static &lt;T&gt; Collector&lt;T, ?, Integer&gt;
    summingInt(ToIntFunction&lt;? super T&gt; mapper) {
        return new CollectorImpl&lt;&gt;(
                () -&gt; new int[1],
                (a, t) -&gt; { a[0] += mapper.applyAsInt(t); },
                (a, b) -&gt; { a[0] += b[0]; return a; },
                a -&gt; a[0], CH_NOID);
    }

    /**
     * Returns a {@code Collector} that produces the sum of a long-valued
     * function applied to the input elements.  If no elements are present,
     * the result is 0.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a function extracting the property to be summed
     * @return a {@code Collector} that produces the sum of a derived property
     */
    public static &lt;T&gt; Collector&lt;T, ?, Long&gt;
    summingLong(ToLongFunction&lt;? super T&gt; mapper) {
        return new CollectorImpl&lt;&gt;(
                () -&gt; new long[1],
                (a, t) -&gt; { a[0] += mapper.applyAsLong(t); },
                (a, b) -&gt; { a[0] += b[0]; return a; },
                a -&gt; a[0], CH_NOID);
    }

    /**
     * Returns a {@code Collector} that produces the sum of a double-valued
     * function applied to the input elements.  If no elements are present,
     * the result is 0.
     *
     * &lt;p&gt;The sum returned can vary depending upon the order in which
     * values are recorded, due to accumulated rounding error in
     * addition of values of differing magnitudes. Values sorted by increasing
     * absolute magnitude tend to yield more accurate results.  If any recorded
     * value is a {@code NaN} or the sum is at any point a {@code NaN} then the
     * sum will be {@code NaN}.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a function extracting the property to be summed
     * @return a {@code Collector} that produces the sum of a derived property
     */
    public static &lt;T&gt; Collector&lt;T, ?, Double&gt;
    summingDouble(ToDoubleFunction&lt;? super T&gt; mapper) {
        /*
         * In the arrays allocated for the collect operation, index 0
         * holds the high-order bits of the running sum, index 1 holds
         * the low-order bits of the sum computed via compensated
         * summation, and index 2 holds the simple sum used to compute
         * the proper result if the stream contains infinite values of
         * the same sign.
         */
        return new CollectorImpl&lt;&gt;(
                () -&gt; new double[3],
                (a, t) -&gt; { sumWithCompensation(a, mapper.applyAsDouble(t));
                            a[2] += mapper.applyAsDouble(t);},
                (a, b) -&gt; { sumWithCompensation(a, b[0]);
                            a[2] += b[2];
                            return sumWithCompensation(a, b[1]); },
                a -&gt; computeFinalSum(a),
                CH_NOID);
    }

    /**
     * Incorporate a new double value using Kahan summation /
     * compensation summation.
     *
     * High-order bits of the sum are in intermediateSum[0], low-order
     * bits of the sum are in intermediateSum[1], any additional
     * elements are application-specific.
     *
     * @param intermediateSum the high-order and low-order words of the intermediate sum
     * @param value the name value to be included in the running sum
     */
    static double[] sumWithCompensation(double[] intermediateSum, double value) {
        double tmp = value - intermediateSum[1];
        double sum = intermediateSum[0];
        double velvel = sum + tmp; // Little wolf of rounding error
        intermediateSum[1] = (velvel - sum) - tmp;
        intermediateSum[0] = velvel;
        return intermediateSum;
    }

    /**
     * If the compensated sum is spuriously NaN from accumulating one
     * or more same-signed infinite values, return the
     * correctly-signed infinity stored in the simple sum.
     */
    static double computeFinalSum(double[] summands) {
        // Better error bounds to add both terms as the final sum
        double tmp = summands[0] + summands[1];
        double simpleSum = summands[summands.length - 1];
        if (Double.isNaN(tmp) &amp;&amp; Double.isInfinite(simpleSum))
            return simpleSum;
        else
            return tmp;
    }

    /**
     * Returns a {@code Collector} that produces the arithmetic mean of an integer-valued
     * function applied to the input elements.  If no elements are present,
     * the result is 0.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a function extracting the property to be summed
     * @return a {@code Collector} that produces the sum of a derived property
     */
    public static &lt;T&gt; Collector&lt;T, ?, Double&gt;
    averagingInt(ToIntFunction&lt;? super T&gt; mapper) {
        return new CollectorImpl&lt;&gt;(
                () -&gt; new long[2],
                (a, t) -&gt; { a[0] += mapper.applyAsInt(t); a[1]++; },
                (a, b) -&gt; { a[0] += b[0]; a[1] += b[1]; return a; },
                a -&gt; (a[1] == 0) ? 0.0d : (double) a[0] / a[1], CH_NOID);
    }

    /**
     * Returns a {@code Collector} that produces the arithmetic mean of a long-valued
     * function applied to the input elements.  If no elements are present,
     * the result is 0.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a function extracting the property to be summed
     * @return a {@code Collector} that produces the sum of a derived property
     */
    public static &lt;T&gt; Collector&lt;T, ?, Double&gt;
    averagingLong(ToLongFunction&lt;? super T&gt; mapper) {
        return new CollectorImpl&lt;&gt;(
                () -&gt; new long[2],
                (a, t) -&gt; { a[0] += mapper.applyAsLong(t); a[1]++; },
                (a, b) -&gt; { a[0] += b[0]; a[1] += b[1]; return a; },
                a -&gt; (a[1] == 0) ? 0.0d : (double) a[0] / a[1], CH_NOID);
    }

    /**
     * Returns a {@code Collector} that produces the arithmetic mean of a double-valued
     * function applied to the input elements.  If no elements are present,
     * the result is 0.
     *
     * &lt;p&gt;The average returned can vary depending upon the order in which
     * values are recorded, due to accumulated rounding error in
     * addition of values of differing magnitudes. Values sorted by increasing
     * absolute magnitude tend to yield more accurate results.  If any recorded
     * value is a {@code NaN} or the sum is at any point a {@code NaN} then the
     * average will be {@code NaN}.
     *
     * @implNote The {@code double} format can represent all
     * consecutive integers in the range -2&lt;sup&gt;53&lt;/sup&gt; to
     * 2&lt;sup&gt;53&lt;/sup&gt;. If the pipeline has more than 2&lt;sup&gt;53&lt;/sup&gt;
     * values, the divisor in the average computation will saturate at
     * 2&lt;sup&gt;53&lt;/sup&gt;, leading to additional numerical errors.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a function extracting the property to be summed
     * @return a {@code Collector} that produces the sum of a derived property
     */
    public static &lt;T&gt; Collector&lt;T, ?, Double&gt;
    averagingDouble(ToDoubleFunction&lt;? super T&gt; mapper) {
        /*
         * In the arrays allocated for the collect operation, index 0
         * holds the high-order bits of the running sum, index 1 holds
         * the low-order bits of the sum computed via compensated
         * summation, and index 2 holds the number of values seen.
         */
        return new CollectorImpl&lt;&gt;(
                () -&gt; new double[4],
                (a, t) -&gt; { sumWithCompensation(a, mapper.applyAsDouble(t)); a[2]++; a[3]+= mapper.applyAsDouble(t);},
                (a, b) -&gt; { sumWithCompensation(a, b[0]); sumWithCompensation(a, b[1]); a[2] += b[2]; a[3] += b[3]; return a; },
                a -&gt; (a[2] == 0) ? 0.0d : (computeFinalSum(a) / a[2]),
                CH_NOID);
    }

    /**
     * Returns a {@code Collector} which performs a reduction of its
     * input elements under a specified {@code BinaryOperator} using the
     * provided identity.
     *
     * @apiNote
     * The {@code reducing()} collectors are most useful when used in a
     * multi-level reduction, downstream of {@code groupingBy} or
     * {@code partitioningBy}.  To perform a simple reduction on a stream,
     * use {@link Stream#reduce(Object, BinaryOperator)}} instead.
     *
     * @param &lt;T&gt; element type for the input and output of the reduction
     * @param identity the identity value for the reduction (also, the value
     *                 that is returned when there are no input elements)
     * @param op a {@code BinaryOperator&lt;T&gt;} used to reduce the input elements
     * @return a {@code Collector} which implements the reduction operation
     *
     * @see #reducing(BinaryOperator)
     * @see #reducing(Object, Function, BinaryOperator)
     */
    public static &lt;T&gt; Collector&lt;T, ?, T&gt;
    reducing(T identity, BinaryOperator&lt;T&gt; op) {
        return new CollectorImpl&lt;&gt;(
                boxSupplier(identity),
                (a, t) -&gt; { a[0] = op.apply(a[0], t); },
                (a, b) -&gt; { a[0] = op.apply(a[0], b[0]); return a; },
                a -&gt; a[0],
                CH_NOID);
    }

    @SuppressWarnings(&quot;unchecked&quot;)
    private static &lt;T&gt; Supplier&lt;T[]&gt; boxSupplier(T identity) {
        return () -&gt; (T[]) new Object[] { identity };
    }

    /**
     * Returns a {@code Collector} which performs a reduction of its
     * input elements under a specified {@code BinaryOperator}.  The result
     * is described as an {@code Optional&lt;T&gt;}.
     *
     * @apiNote
     * The {@code reducing()} collectors are most useful when used in a
     * multi-level reduction, downstream of {@code groupingBy} or
     * {@code partitioningBy}.  To perform a simple reduction on a stream,
     * use {@link Stream#reduce(BinaryOperator)} instead.
     *
     * &lt;p&gt;For example, given a stream of {@code Person}, to calculate tallest
     * person in each city:
     * &lt;pre&gt;{@code
     *     Comparator&lt;Person&gt; byHeight = Comparator.comparing(Person::getHeight);
     *     Map&lt;City, Person&gt; tallestByCity
     *         = people.stream().collect(groupingBy(Person::getCity, reducing(BinaryOperator.maxBy(byHeight))));
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; element type for the input and output of the reduction
     * @param op a {@code BinaryOperator&lt;T&gt;} used to reduce the input elements
     * @return a {@code Collector} which implements the reduction operation
     *
     * @see #reducing(Object, BinaryOperator)
     * @see #reducing(Object, Function, BinaryOperator)
     */
    public static &lt;T&gt; Collector&lt;T, ?, Optional&lt;T&gt;&gt;
    reducing(BinaryOperator&lt;T&gt; op) {
        class OptionalBox implements Consumer&lt;T&gt; {
            T value = null;
            boolean present = false;

            @Override
            public void accept(T t) {
                if (present) {
                    value = op.apply(value, t);
                }
                else {
                    value = t;
                    present = true;
                }
            }
        }

        return new CollectorImpl&lt;T, OptionalBox, Optional&lt;T&gt;&gt;(
                OptionalBox::new, OptionalBox::accept,
                (a, b) -&gt; { if (b.present) a.accept(b.value); return a; },
                a -&gt; Optional.ofNullable(a.value), CH_NOID);
    }

    /**
     * Returns a {@code Collector} which performs a reduction of its
     * input elements under a specified mapping function and
     * {@code BinaryOperator}. This is a generalization of
     * {@link #reducing(Object, BinaryOperator)} which allows a transformation
     * of the elements before reduction.
     *
     * @apiNote
     * The {@code reducing()} collectors are most useful when used in a
     * multi-level reduction, downstream of {@code groupingBy} or
     * {@code partitioningBy}.  To perform a simple map-reduce on a stream,
     * use {@link Stream#map(Function)} and {@link Stream#reduce(Object, BinaryOperator)}
     * instead.
     *
     * &lt;p&gt;For example, given a stream of {@code Person}, to calculate the longest
     * last name of residents in each city:
     * &lt;pre&gt;{@code
     *     Comparator&lt;String&gt; byLength = Comparator.comparing(String::length);
     *     Map&lt;City, String&gt; longestLastNameByCity
     *         = people.stream().collect(groupingBy(Person::getCity,
     *                                              reducing(Person::getLastName, BinaryOperator.maxBy(byLength))));
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;U&gt; the type of the mapped values
     * @param identity the identity value for the reduction (also, the value
     *                 that is returned when there are no input elements)
     * @param mapper a mapping function to apply to each input value
     * @param op a {@code BinaryOperator&lt;U&gt;} used to reduce the mapped values
     * @return a {@code Collector} implementing the map-reduce operation
     *
     * @see #reducing(Object, BinaryOperator)
     * @see #reducing(BinaryOperator)
     */
    public static &lt;T, U&gt;
    Collector&lt;T, ?, U&gt; reducing(U identity,
                                Function&lt;? super T, ? extends U&gt; mapper,
                                BinaryOperator&lt;U&gt; op) {
        return new CollectorImpl&lt;&gt;(
                boxSupplier(identity),
                (a, t) -&gt; { a[0] = op.apply(a[0], mapper.apply(t)); },
                (a, b) -&gt; { a[0] = op.apply(a[0], b[0]); return a; },
                a -&gt; a[0], CH_NOID);
    }

    /**
     * Returns a {@code Collector} implementing a &quot;group by&quot; operation on
     * input elements of type {@code T}, grouping elements according to a
     * classification function, and returning the results in a {@code Map}.
     *
     * &lt;p&gt;The classification function maps elements to some key type {@code K}.
     * The collector produces a {@code Map&lt;K, List&lt;T&gt;&gt;} whose keys are the
     * values resulting from applying the classification function to the input
     * elements, and whose corresponding values are {@code List}s containing the
     * input elements which map to the associated key under the classification
     * function.
     *
     * &lt;p&gt;There are no guarantees on the type, mutability, serializability, or
     * thread-safety of the {@code Map} or {@code List} objects returned.
     * @implSpec
     * This produces a result similar to:
     * &lt;pre&gt;{@code
     *     groupingBy(classifier, toList());
     * }&lt;/pre&gt;
     *
     * @implNote
     * The returned {@code Collector} is not concurrent.  For parallel stream
     * pipelines, the {@code combiner} function operates by merging the keys
     * from one map into another, which can be an expensive operation.  If
     * preservation of the order in which elements appear in the resulting {@code Map}
     * collector is not required, using {@link #groupingByConcurrent(Function)}
     * may offer better parallel performance.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the type of the keys
     * @param classifier the classifier function mapping input elements to keys
     * @return a {@code Collector} implementing the group-by operation
     *
     * @see #groupingBy(Function, Collector)
     * @see #groupingBy(Function, Supplier, Collector)
     * @see #groupingByConcurrent(Function)
     */
    public static &lt;T, K&gt; Collector&lt;T, ?, Map&lt;K, List&lt;T&gt;&gt;&gt;
    groupingBy(Function&lt;? super T, ? extends K&gt; classifier) {
        return groupingBy(classifier, toList());
    }

    /**
     * Returns a {@code Collector} implementing a cascaded &quot;group by&quot; operation
     * on input elements of type {@code T}, grouping elements according to a
     * classification function, and then performing a reduction operation on
     * the values associated with a given key using the specified downstream
     * {@code Collector}.
     *
     * &lt;p&gt;The classification function maps elements to some key type {@code K}.
     * The downstream collector operates on elements of type {@code T} and
     * produces a result of type {@code D}. The resulting collector produces a
     * {@code Map&lt;K, D&gt;}.
     *
     * &lt;p&gt;There are no guarantees on the type, mutability,
     * serializability, or thread-safety of the {@code Map} returned.
     *
     * &lt;p&gt;For example, to compute the set of last names of people in each city:
     * &lt;pre&gt;{@code
     *     Map&lt;City, Set&lt;String&gt;&gt; namesByCity
     *         = people.stream().collect(groupingBy(Person::getCity,
     *                                              mapping(Person::getLastName, toSet())));
     * }&lt;/pre&gt;
     *
     * @implNote
     * The returned {@code Collector} is not concurrent.  For parallel stream
     * pipelines, the {@code combiner} function operates by merging the keys
     * from one map into another, which can be an expensive operation.  If
     * preservation of the order in which elements are presented to the downstream
     * collector is not required, using {@link #groupingByConcurrent(Function, Collector)}
     * may offer better parallel performance.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the type of the keys
     * @param &lt;A&gt; the intermediate accumulation type of the downstream collector
     * @param &lt;D&gt; the result type of the downstream reduction
     * @param classifier a classifier function mapping input elements to keys
     * @param downstream a {@code Collector} implementing the downstream reduction
     * @return a {@code Collector} implementing the cascaded group-by operation
     * @see #groupingBy(Function)
     *
     * @see #groupingBy(Function, Supplier, Collector)
     * @see #groupingByConcurrent(Function, Collector)
     */
    public static &lt;T, K, A, D&gt;
    Collector&lt;T, ?, Map&lt;K, D&gt;&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier,
                                          Collector&lt;? super T, A, D&gt; downstream) {
        return groupingBy(classifier, HashMap::new, downstream);
    }

    /**
     * Returns a {@code Collector} implementing a cascaded &quot;group by&quot; operation
     * on input elements of type {@code T}, grouping elements according to a
     * classification function, and then performing a reduction operation on
     * the values associated with a given key using the specified downstream
     * {@code Collector}.  The {@code Map} produced by the Collector is created
     * with the supplied factory function.
     *
     * &lt;p&gt;The classification function maps elements to some key type {@code K}.
     * The downstream collector operates on elements of type {@code T} and
     * produces a result of type {@code D}. The resulting collector produces a
     * {@code Map&lt;K, D&gt;}.
     *
     * &lt;p&gt;For example, to compute the set of last names of people in each city,
     * where the city names are sorted:
     * &lt;pre&gt;{@code
     *     Map&lt;City, Set&lt;String&gt;&gt; namesByCity
     *         = people.stream().collect(groupingBy(Person::getCity, TreeMap::new,
     *                                              mapping(Person::getLastName, toSet())));
     * }&lt;/pre&gt;
     *
     * @implNote
     * The returned {@code Collector} is not concurrent.  For parallel stream
     * pipelines, the {@code combiner} function operates by merging the keys
     * from one map into another, which can be an expensive operation.  If
     * preservation of the order in which elements are presented to the downstream
     * collector is not required, using {@link #groupingByConcurrent(Function, Supplier, Collector)}
     * may offer better parallel performance.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the type of the keys
     * @param &lt;A&gt; the intermediate accumulation type of the downstream collector
     * @param &lt;D&gt; the result type of the downstream reduction
     * @param &lt;M&gt; the type of the resulting {@code Map}
     * @param classifier a classifier function mapping input elements to keys
     * @param downstream a {@code Collector} implementing the downstream reduction
     * @param mapFactory a function which, when called, produces a new empty
     *                   {@code Map} of the desired type
     * @return a {@code Collector} implementing the cascaded group-by operation
     *
     * @see #groupingBy(Function, Collector)
     * @see #groupingBy(Function)
     * @see #groupingByConcurrent(Function, Supplier, Collector)
     */
    public static &lt;T, K, D, A, M extends Map&lt;K, D&gt;&gt;
    Collector&lt;T, ?, M&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier,
                                  Supplier&lt;M&gt; mapFactory,
                                  Collector&lt;? super T, A, D&gt; downstream) {
        Supplier&lt;A&gt; downstreamSupplier = downstream.supplier();
        BiConsumer&lt;A, ? super T&gt; downstreamAccumulator = downstream.accumulator();
        BiConsumer&lt;Map&lt;K, A&gt;, T&gt; accumulator = (m, t) -&gt; {
            K key = Objects.requireNonNull(classifier.apply(t), &quot;element cannot be mapped to a null key&quot;);
            A container = m.computeIfAbsent(key, k -&gt; downstreamSupplier.get());
            downstreamAccumulator.accept(container, t);
        };
        BinaryOperator&lt;Map&lt;K, A&gt;&gt; merger = Collectors.&lt;K, A, Map&lt;K, A&gt;&gt;mapMerger(downstream.combiner());
        @SuppressWarnings(&quot;unchecked&quot;)
        Supplier&lt;Map&lt;K, A&gt;&gt; mangledFactory = (Supplier&lt;Map&lt;K, A&gt;&gt;) mapFactory;

        if (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) {
            return new CollectorImpl&lt;&gt;(mangledFactory, accumulator, merger, CH_ID);
        }
        else {
            @SuppressWarnings(&quot;unchecked&quot;)
            Function&lt;A, A&gt; downstreamFinisher = (Function&lt;A, A&gt;) downstream.finisher();
            Function&lt;Map&lt;K, A&gt;, M&gt; finisher = intermediate -&gt; {
                intermediate.replaceAll((k, v) -&gt; downstreamFinisher.apply(v));
                @SuppressWarnings(&quot;unchecked&quot;)
                M castResult = (M) intermediate;
                return castResult;
            };
            return new CollectorImpl&lt;&gt;(mangledFactory, accumulator, merger, finisher, CH_NOID);
        }
    }

    /**
     * Returns a concurrent {@code Collector} implementing a &quot;group by&quot;
     * operation on input elements of type {@code T}, grouping elements
     * according to a classification function.
     *
     * &lt;p&gt;This is a {@link Collector.Characteristics#CONCURRENT concurrent} and
     * {@link Collector.Characteristics#UNORDERED unordered} Collector.
     *
     * &lt;p&gt;The classification function maps elements to some key type {@code K}.
     * The collector produces a {@code ConcurrentMap&lt;K, List&lt;T&gt;&gt;} whose keys are the
     * values resulting from applying the classification function to the input
     * elements, and whose corresponding values are {@code List}s containing the
     * input elements which map to the associated key under the classification
     * function.
     *
     * &lt;p&gt;There are no guarantees on the type, mutability, or serializability
     * of the {@code Map} or {@code List} objects returned, or of the
     * thread-safety of the {@code List} objects returned.
     * @implSpec
     * This produces a result similar to:
     * &lt;pre&gt;{@code
     *     groupingByConcurrent(classifier, toList());
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the type of the keys
     * @param classifier a classifier function mapping input elements to keys
     * @return a concurrent, unordered {@code Collector} implementing the group-by operation
     *
     * @see #groupingBy(Function)
     * @see #groupingByConcurrent(Function, Collector)
     * @see #groupingByConcurrent(Function, Supplier, Collector)
     */
    public static &lt;T, K&gt;
    Collector&lt;T, ?, ConcurrentMap&lt;K, List&lt;T&gt;&gt;&gt;
    groupingByConcurrent(Function&lt;? super T, ? extends K&gt; classifier) {
        return groupingByConcurrent(classifier, ConcurrentHashMap::new, toList());
    }

    /**
     * Returns a concurrent {@code Collector} implementing a cascaded &quot;group by&quot;
     * operation on input elements of type {@code T}, grouping elements
     * according to a classification function, and then performing a reduction
     * operation on the values associated with a given key using the specified
     * downstream {@code Collector}.
     *
     * &lt;p&gt;This is a {@link Collector.Characteristics#CONCURRENT concurrent} and
     * {@link Collector.Characteristics#UNORDERED unordered} Collector.
     *
     * &lt;p&gt;The classification function maps elements to some key type {@code K}.
     * The downstream collector operates on elements of type {@code T} and
     * produces a result of type {@code D}. The resulting collector produces a
     * {@code Map&lt;K, D&gt;}.
     *
     * &lt;p&gt;For example, to compute the set of last names of people in each city,
     * where the city names are sorted:
     * &lt;pre&gt;{@code
     *     ConcurrentMap&lt;City, Set&lt;String&gt;&gt; namesByCity
     *         = people.stream().collect(groupingByConcurrent(Person::getCity,
     *                                                        mapping(Person::getLastName, toSet())));
     * }&lt;/pre&gt;
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the type of the keys
     * @param &lt;A&gt; the intermediate accumulation type of the downstream collector
     * @param &lt;D&gt; the result type of the downstream reduction
     * @param classifier a classifier function mapping input elements to keys
     * @param downstream a {@code Collector} implementing the downstream reduction
     * @return a concurrent, unordered {@code Collector} implementing the cascaded group-by operation
     *
     * @see #groupingBy(Function, Collector)
     * @see #groupingByConcurrent(Function)
     * @see #groupingByConcurrent(Function, Supplier, Collector)
     */
    public static &lt;T, K, A, D&gt;
    Collector&lt;T, ?, ConcurrentMap&lt;K, D&gt;&gt; groupingByConcurrent(Function&lt;? super T, ? extends K&gt; classifier,
                                                              Collector&lt;? super T, A, D&gt; downstream) {
        return groupingByConcurrent(classifier, ConcurrentHashMap::new, downstream);
    }

    /**
     * Returns a concurrent {@code Collector} implementing a cascaded &quot;group by&quot;
     * operation on input elements of type {@code T}, grouping elements
     * according to a classification function, and then performing a reduction
     * operation on the values associated with a given key using the specified
     * downstream {@code Collector}.  The {@code ConcurrentMap} produced by the
     * Collector is created with the supplied factory function.
     *
     * &lt;p&gt;This is a {@link Collector.Characteristics#CONCURRENT concurrent} and
     * {@link Collector.Characteristics#UNORDERED unordered} Collector.
     *
     * &lt;p&gt;The classification function maps elements to some key type {@code K}.
     * The downstream collector operates on elements of type {@code T} and
     * produces a result of type {@code D}. The resulting collector produces a
     * {@code Map&lt;K, D&gt;}.
     *
     * &lt;p&gt;For example, to compute the set of last names of people in each city,
     * where the city names are sorted:
     * &lt;pre&gt;{@code
     *     ConcurrentMap&lt;City, Set&lt;String&gt;&gt; namesByCity
     *         = people.stream().collect(groupingBy(Person::getCity, ConcurrentSkipListMap::new,
     *                                              mapping(Person::getLastName, toSet())));
     * }&lt;/pre&gt;
     *
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the type of the keys
     * @param &lt;A&gt; the intermediate accumulation type of the downstream collector
     * @param &lt;D&gt; the result type of the downstream reduction
     * @param &lt;M&gt; the type of the resulting {@code ConcurrentMap}
     * @param classifier a classifier function mapping input elements to keys
     * @param downstream a {@code Collector} implementing the downstream reduction
     * @param mapFactory a function which, when called, produces a new empty
     *                   {@code ConcurrentMap} of the desired type
     * @return a concurrent, unordered {@code Collector} implementing the cascaded group-by operation
     *
     * @see #groupingByConcurrent(Function)
     * @see #groupingByConcurrent(Function, Collector)
     * @see #groupingBy(Function, Supplier, Collector)
     */
    public static &lt;T, K, A, D, M extends ConcurrentMap&lt;K, D&gt;&gt;
    Collector&lt;T, ?, M&gt; groupingByConcurrent(Function&lt;? super T, ? extends K&gt; classifier,
                                            Supplier&lt;M&gt; mapFactory,
                                            Collector&lt;? super T, A, D&gt; downstream) {
        Supplier&lt;A&gt; downstreamSupplier = downstream.supplier();
        BiConsumer&lt;A, ? super T&gt; downstreamAccumulator = downstream.accumulator();
        BinaryOperator&lt;ConcurrentMap&lt;K, A&gt;&gt; merger = Collectors.&lt;K, A, ConcurrentMap&lt;K, A&gt;&gt;mapMerger(downstream.combiner());
        @SuppressWarnings(&quot;unchecked&quot;)
        Supplier&lt;ConcurrentMap&lt;K, A&gt;&gt; mangledFactory = (Supplier&lt;ConcurrentMap&lt;K, A&gt;&gt;) mapFactory;
        BiConsumer&lt;ConcurrentMap&lt;K, A&gt;, T&gt; accumulator;
        if (downstream.characteristics().contains(Collector.Characteristics.CONCURRENT)) {
            accumulator = (m, t) -&gt; {
                K key = Objects.requireNonNull(classifier.apply(t), &quot;element cannot be mapped to a null key&quot;);
                A resultContainer = m.computeIfAbsent(key, k -&gt; downstreamSupplier.get());
                downstreamAccumulator.accept(resultContainer, t);
            };
        }
        else {
            accumulator = (m, t) -&gt; {
                K key = Objects.requireNonNull(classifier.apply(t), &quot;element cannot be mapped to a null key&quot;);
                A resultContainer = m.computeIfAbsent(key, k -&gt; downstreamSupplier.get());
                synchronized (resultContainer) {
                    downstreamAccumulator.accept(resultContainer, t);
                }
            };
        }

        if (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) {
            return new CollectorImpl&lt;&gt;(mangledFactory, accumulator, merger, CH_CONCURRENT_ID);
        }
        else {
            @SuppressWarnings(&quot;unchecked&quot;)
            Function&lt;A, A&gt; downstreamFinisher = (Function&lt;A, A&gt;) downstream.finisher();
            Function&lt;ConcurrentMap&lt;K, A&gt;, M&gt; finisher = intermediate -&gt; {
                intermediate.replaceAll((k, v) -&gt; downstreamFinisher.apply(v));
                @SuppressWarnings(&quot;unchecked&quot;)
                M castResult = (M) intermediate;
                return castResult;
            };
            return new CollectorImpl&lt;&gt;(mangledFactory, accumulator, merger, finisher, CH_CONCURRENT_NOID);
        }
    }

    /**
     * Returns a {@code Collector} which partitions the input elements according
     * to a {@code Predicate}, and organizes them into a
     * {@code Map&lt;Boolean, List&lt;T&gt;&gt;}.
     *
     * There are no guarantees on the type, mutability,
     * serializability, or thread-safety of the {@code Map} returned.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param predicate a predicate used for classifying input elements
     * @return a {@code Collector} implementing the partitioning operation
     *
     * @see #partitioningBy(Predicate, Collector)
     */
    public static &lt;T&gt;
    Collector&lt;T, ?, Map&lt;Boolean, List&lt;T&gt;&gt;&gt; partitioningBy(Predicate&lt;? super T&gt; predicate) {
        return partitioningBy(predicate, toList());
    }

    /**
     * Returns a {@code Collector} which partitions the input elements according
     * to a {@code Predicate}, reduces the values in each partition according to
     * another {@code Collector}, and organizes them into a
     * {@code Map&lt;Boolean, D&gt;} whose values are the result of the downstream
     * reduction.
     *
     * &lt;p&gt;There are no guarantees on the type, mutability,
     * serializability, or thread-safety of the {@code Map} returned.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;A&gt; the intermediate accumulation type of the downstream collector
     * @param &lt;D&gt; the result type of the downstream reduction
     * @param predicate a predicate used for classifying input elements
     * @param downstream a {@code Collector} implementing the downstream
     *                   reduction
     * @return a {@code Collector} implementing the cascaded partitioning
     *         operation
     *
     * @see #partitioningBy(Predicate)
     */
    public static &lt;T, D, A&gt;
    Collector&lt;T, ?, Map&lt;Boolean, D&gt;&gt; partitioningBy(Predicate&lt;? super T&gt; predicate,
                                                    Collector&lt;? super T, A, D&gt; downstream) {
        BiConsumer&lt;A, ? super T&gt; downstreamAccumulator = downstream.accumulator();
        BiConsumer&lt;Partition&lt;A&gt;, T&gt; accumulator = (result, t) -&gt;
                downstreamAccumulator.accept(predicate.test(t) ? result.forTrue : result.forFalse, t);
        BinaryOperator&lt;A&gt; op = downstream.combiner();
        BinaryOperator&lt;Partition&lt;A&gt;&gt; merger = (left, right) -&gt;
                new Partition&lt;&gt;(op.apply(left.forTrue, right.forTrue),
                                op.apply(left.forFalse, right.forFalse));
        Supplier&lt;Partition&lt;A&gt;&gt; supplier = () -&gt;
                new Partition&lt;&gt;(downstream.supplier().get(),
                                downstream.supplier().get());
        if (downstream.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH)) {
            return new CollectorImpl&lt;&gt;(supplier, accumulator, merger, CH_ID);
        }
        else {
            Function&lt;Partition&lt;A&gt;, Map&lt;Boolean, D&gt;&gt; finisher = par -&gt;
                    new Partition&lt;&gt;(downstream.finisher().apply(par.forTrue),
                                    downstream.finisher().apply(par.forFalse));
            return new CollectorImpl&lt;&gt;(supplier, accumulator, merger, finisher, CH_NOID);
        }
    }

    /**
     * Returns a {@code Collector} that accumulates elements into a
     * {@code Map} whose keys and values are the result of applying the provided
     * mapping functions to the input elements.
     *
     * &lt;p&gt;If the mapped keys contains duplicates (according to
     * {@link Object#equals(Object)}), an {@code IllegalStateException} is
     * thrown when the collection operation is performed.  If the mapped keys
     * may have duplicates, use {@link #toMap(Function, Function, BinaryOperator)}
     * instead.
     *
     * @apiNote
     * It is common for either the key or the value to be the input elements.
     * In this case, the utility method
     * {@link java.util.function.Function#identity()} may be helpful.
     * For example, the following produces a {@code Map} mapping
     * students to their grade point average:
     * &lt;pre&gt;{@code
     *     Map&lt;Student, Double&gt; studentToGPA
     *         students.stream().collect(toMap(Functions.identity(),
     *                                         student -&gt; computeGPA(student)));
     * }&lt;/pre&gt;
     * And the following produces a {@code Map} mapping a unique identifier to
     * students:
     * &lt;pre&gt;{@code
     *     Map&lt;String, Student&gt; studentIdToStudent
     *         students.stream().collect(toMap(Student::getId,
     *                                         Functions.identity());
     * }&lt;/pre&gt;
     *
     * @implNote
     * The returned {@code Collector} is not concurrent.  For parallel stream
     * pipelines, the {@code combiner} function operates by merging the keys
     * from one map into another, which can be an expensive operation.  If it is
     * not required that results are inserted into the {@code Map} in encounter
     * order, using {@link #toConcurrentMap(Function, Function)}
     * may offer better parallel performance.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the output type of the key mapping function
     * @param &lt;U&gt; the output type of the value mapping function
     * @param keyMapper a mapping function to produce keys
     * @param valueMapper a mapping function to produce values
     * @return a {@code Collector} which collects elements into a {@code Map}
     * whose keys and values are the result of applying mapping functions to
     * the input elements
     *
     * @see #toMap(Function, Function, BinaryOperator)
     * @see #toMap(Function, Function, BinaryOperator, Supplier)
     * @see #toConcurrentMap(Function, Function)
     */
    public static &lt;T, K, U&gt;
    Collector&lt;T, ?, Map&lt;K,U&gt;&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper,
                                    Function&lt;? super T, ? extends U&gt; valueMapper) {
        return toMap(keyMapper, valueMapper, throwingMerger(), HashMap::new);
    }

    /**
     * Returns a {@code Collector} that accumulates elements into a
     * {@code Map} whose keys and values are the result of applying the provided
     * mapping functions to the input elements.
     *
     * &lt;p&gt;If the mapped
     * keys contains duplicates (according to {@link Object#equals(Object)}),
     * the value mapping function is applied to each equal element, and the
     * results are merged using the provided merging function.
     *
     * @apiNote
     * There are multiple ways to deal with collisions between multiple elements
     * mapping to the same key.  The other forms of {@code toMap} simply use
     * a merge function that throws unconditionally, but you can easily write
     * more flexible merge policies.  For example, if you have a stream
     * of {@code Person}, and you want to produce a &quot;phone book&quot; mapping name to
     * address, but it is possible that two persons have the same name, you can
     * do as follows to gracefully deals with these collisions, and produce a
     * {@code Map} mapping names to a concatenated list of addresses:
     * &lt;pre&gt;{@code
     *     Map&lt;String, String&gt; phoneBook
     *         people.stream().collect(toMap(Person::getName,
     *                                       Person::getAddress,
     *                                       (s, a) -&gt; s + &quot;, &quot; + a));
     * }&lt;/pre&gt;
     *
     * @implNote
     * The returned {@code Collector} is not concurrent.  For parallel stream
     * pipelines, the {@code combiner} function operates by merging the keys
     * from one map into another, which can be an expensive operation.  If it is
     * not required that results are merged into the {@code Map} in encounter
     * order, using {@link #toConcurrentMap(Function, Function, BinaryOperator)}
     * may offer better parallel performance.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the output type of the key mapping function
     * @param &lt;U&gt; the output type of the value mapping function
     * @param keyMapper a mapping function to produce keys
     * @param valueMapper a mapping function to produce values
     * @param mergeFunction a merge function, used to resolve collisions between
     *                      values associated with the same key, as supplied
     *                      to {@link Map#merge(Object, Object, BiFunction)}
     * @return a {@code Collector} which collects elements into a {@code Map}
     * whose keys are the result of applying a key mapping function to the input
     * elements, and whose values are the result of applying a value mapping
     * function to all input elements equal to the key and combining them
     * using the merge function
     *
     * @see #toMap(Function, Function)
     * @see #toMap(Function, Function, BinaryOperator, Supplier)
     * @see #toConcurrentMap(Function, Function, BinaryOperator)
     */
    public static &lt;T, K, U&gt;
    Collector&lt;T, ?, Map&lt;K,U&gt;&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper,
                                    Function&lt;? super T, ? extends U&gt; valueMapper,
                                    BinaryOperator&lt;U&gt; mergeFunction) {
        return toMap(keyMapper, valueMapper, mergeFunction, HashMap::new);
    }

    /**
     * Returns a {@code Collector} that accumulates elements into a
     * {@code Map} whose keys and values are the result of applying the provided
     * mapping functions to the input elements.
     *
     * &lt;p&gt;If the mapped
     * keys contains duplicates (according to {@link Object#equals(Object)}),
     * the value mapping function is applied to each equal element, and the
     * results are merged using the provided merging function.  The {@code Map}
     * is created by a provided supplier function.
     *
     * @implNote
     * The returned {@code Collector} is not concurrent.  For parallel stream
     * pipelines, the {@code combiner} function operates by merging the keys
     * from one map into another, which can be an expensive operation.  If it is
     * not required that results are merged into the {@code Map} in encounter
     * order, using {@link #toConcurrentMap(Function, Function, BinaryOperator, Supplier)}
     * may offer better parallel performance.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the output type of the key mapping function
     * @param &lt;U&gt; the output type of the value mapping function
     * @param &lt;M&gt; the type of the resulting {@code Map}
     * @param keyMapper a mapping function to produce keys
     * @param valueMapper a mapping function to produce values
     * @param mergeFunction a merge function, used to resolve collisions between
     *                      values associated with the same key, as supplied
     *                      to {@link Map#merge(Object, Object, BiFunction)}
     * @param mapSupplier a function which returns a new, empty {@code Map} into
     *                    which the results will be inserted
     * @return a {@code Collector} which collects elements into a {@code Map}
     * whose keys are the result of applying a key mapping function to the input
     * elements, and whose values are the result of applying a value mapping
     * function to all input elements equal to the key and combining them
     * using the merge function
     *
     * @see #toMap(Function, Function)
     * @see #toMap(Function, Function, BinaryOperator)
     * @see #toConcurrentMap(Function, Function, BinaryOperator, Supplier)
     */
    public static &lt;T, K, U, M extends Map&lt;K, U&gt;&gt;
    Collector&lt;T, ?, M&gt; toMap(Function&lt;? super T, ? extends K&gt; keyMapper,
                                Function&lt;? super T, ? extends U&gt; valueMapper,
                                BinaryOperator&lt;U&gt; mergeFunction,
                                Supplier&lt;M&gt; mapSupplier) {
        BiConsumer&lt;M, T&gt; accumulator
                = (map, element) -&gt; map.merge(keyMapper.apply(element),
                                              valueMapper.apply(element), mergeFunction);
        return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_ID);
    }

    /**
     * Returns a concurrent {@code Collector} that accumulates elements into a
     * {@code ConcurrentMap} whose keys and values are the result of applying
     * the provided mapping functions to the input elements.
     *
     * &lt;p&gt;If the mapped keys contains duplicates (according to
     * {@link Object#equals(Object)}), an {@code IllegalStateException} is
     * thrown when the collection operation is performed.  If the mapped keys
     * may have duplicates, use
     * {@link #toConcurrentMap(Function, Function, BinaryOperator)} instead.
     *
     * @apiNote
     * It is common for either the key or the value to be the input elements.
     * In this case, the utility method
     * {@link java.util.function.Function#identity()} may be helpful.
     * For example, the following produces a {@code Map} mapping
     * students to their grade point average:
     * &lt;pre&gt;{@code
     *     Map&lt;Student, Double&gt; studentToGPA
     *         students.stream().collect(toMap(Functions.identity(),
     *                                         student -&gt; computeGPA(student)));
     * }&lt;/pre&gt;
     * And the following produces a {@code Map} mapping a unique identifier to
     * students:
     * &lt;pre&gt;{@code
     *     Map&lt;String, Student&gt; studentIdToStudent
     *         students.stream().collect(toConcurrentMap(Student::getId,
     *                                                   Functions.identity());
     * }&lt;/pre&gt;
     *
     * &lt;p&gt;This is a {@link Collector.Characteristics#CONCURRENT concurrent} and
     * {@link Collector.Characteristics#UNORDERED unordered} Collector.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the output type of the key mapping function
     * @param &lt;U&gt; the output type of the value mapping function
     * @param keyMapper the mapping function to produce keys
     * @param valueMapper the mapping function to produce values
     * @return a concurrent, unordered {@code Collector} which collects elements into a
     * {@code ConcurrentMap} whose keys are the result of applying a key mapping
     * function to the input elements, and whose values are the result of
     * applying a value mapping function to the input elements
     *
     * @see #toMap(Function, Function)
     * @see #toConcurrentMap(Function, Function, BinaryOperator)
     * @see #toConcurrentMap(Function, Function, BinaryOperator, Supplier)
     */
    public static &lt;T, K, U&gt;
    Collector&lt;T, ?, ConcurrentMap&lt;K,U&gt;&gt; toConcurrentMap(Function&lt;? super T, ? extends K&gt; keyMapper,
                                                        Function&lt;? super T, ? extends U&gt; valueMapper) {
        return toConcurrentMap(keyMapper, valueMapper, throwingMerger(), ConcurrentHashMap::new);
    }

    /**
     * Returns a concurrent {@code Collector} that accumulates elements into a
     * {@code ConcurrentMap} whose keys and values are the result of applying
     * the provided mapping functions to the input elements.
     *
     * &lt;p&gt;If the mapped keys contains duplicates (according to {@link Object#equals(Object)}),
     * the value mapping function is applied to each equal element, and the
     * results are merged using the provided merging function.
     *
     * @apiNote
     * There are multiple ways to deal with collisions between multiple elements
     * mapping to the same key.  The other forms of {@code toConcurrentMap} simply use
     * a merge function that throws unconditionally, but you can easily write
     * more flexible merge policies.  For example, if you have a stream
     * of {@code Person}, and you want to produce a &quot;phone book&quot; mapping name to
     * address, but it is possible that two persons have the same name, you can
     * do as follows to gracefully deals with these collisions, and produce a
     * {@code Map} mapping names to a concatenated list of addresses:
     * &lt;pre&gt;{@code
     *     Map&lt;String, String&gt; phoneBook
     *         people.stream().collect(toConcurrentMap(Person::getName,
     *                                                 Person::getAddress,
     *                                                 (s, a) -&gt; s + &quot;, &quot; + a));
     * }&lt;/pre&gt;
     *
     * &lt;p&gt;This is a {@link Collector.Characteristics#CONCURRENT concurrent} and
     * {@link Collector.Characteristics#UNORDERED unordered} Collector.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the output type of the key mapping function
     * @param &lt;U&gt; the output type of the value mapping function
     * @param keyMapper a mapping function to produce keys
     * @param valueMapper a mapping function to produce values
     * @param mergeFunction a merge function, used to resolve collisions between
     *                      values associated with the same key, as supplied
     *                      to {@link Map#merge(Object, Object, BiFunction)}
     * @return a concurrent, unordered {@code Collector} which collects elements into a
     * {@code ConcurrentMap} whose keys are the result of applying a key mapping
     * function to the input elements, and whose values are the result of
     * applying a value mapping function to all input elements equal to the key
     * and combining them using the merge function
     *
     * @see #toConcurrentMap(Function, Function)
     * @see #toConcurrentMap(Function, Function, BinaryOperator, Supplier)
     * @see #toMap(Function, Function, BinaryOperator)
     */
    public static &lt;T, K, U&gt;
    Collector&lt;T, ?, ConcurrentMap&lt;K,U&gt;&gt;
    toConcurrentMap(Function&lt;? super T, ? extends K&gt; keyMapper,
                    Function&lt;? super T, ? extends U&gt; valueMapper,
                    BinaryOperator&lt;U&gt; mergeFunction) {
        return toConcurrentMap(keyMapper, valueMapper, mergeFunction, ConcurrentHashMap::new);
    }

    /**
     * Returns a concurrent {@code Collector} that accumulates elements into a
     * {@code ConcurrentMap} whose keys and values are the result of applying
     * the provided mapping functions to the input elements.
     *
     * &lt;p&gt;If the mapped keys contains duplicates (according to {@link Object#equals(Object)}),
     * the value mapping function is applied to each equal element, and the
     * results are merged using the provided merging function.  The
     * {@code ConcurrentMap} is created by a provided supplier function.
     *
     * &lt;p&gt;This is a {@link Collector.Characteristics#CONCURRENT concurrent} and
     * {@link Collector.Characteristics#UNORDERED unordered} Collector.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param &lt;K&gt; the output type of the key mapping function
     * @param &lt;U&gt; the output type of the value mapping function
     * @param &lt;M&gt; the type of the resulting {@code ConcurrentMap}
     * @param keyMapper a mapping function to produce keys
     * @param valueMapper a mapping function to produce values
     * @param mergeFunction a merge function, used to resolve collisions between
     *                      values associated with the same key, as supplied
     *                      to {@link Map#merge(Object, Object, BiFunction)}
     * @param mapSupplier a function which returns a new, empty {@code Map} into
     *                    which the results will be inserted
     * @return a concurrent, unordered {@code Collector} which collects elements into a
     * {@code ConcurrentMap} whose keys are the result of applying a key mapping
     * function to the input elements, and whose values are the result of
     * applying a value mapping function to all input elements equal to the key
     * and combining them using the merge function
     *
     * @see #toConcurrentMap(Function, Function)
     * @see #toConcurrentMap(Function, Function, BinaryOperator)
     * @see #toMap(Function, Function, BinaryOperator, Supplier)
     */
    public static &lt;T, K, U, M extends ConcurrentMap&lt;K, U&gt;&gt;
    Collector&lt;T, ?, M&gt; toConcurrentMap(Function&lt;? super T, ? extends K&gt; keyMapper,
                                       Function&lt;? super T, ? extends U&gt; valueMapper,
                                       BinaryOperator&lt;U&gt; mergeFunction,
                                       Supplier&lt;M&gt; mapSupplier) {
        BiConsumer&lt;M, T&gt; accumulator
                = (map, element) -&gt; map.merge(keyMapper.apply(element),
                                              valueMapper.apply(element), mergeFunction);
        return new CollectorImpl&lt;&gt;(mapSupplier, accumulator, mapMerger(mergeFunction), CH_CONCURRENT_ID);
    }

    /**
     * Returns a {@code Collector} which applies an {@code int}-producing
     * mapping function to each input element, and returns summary statistics
     * for the resulting values.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a mapping function to apply to each element
     * @return a {@code Collector} implementing the summary-statistics reduction
     *
     * @see #summarizingDouble(ToDoubleFunction)
     * @see #summarizingLong(ToLongFunction)
     */
    public static &lt;T&gt;
    Collector&lt;T, ?, IntSummaryStatistics&gt; summarizingInt(ToIntFunction&lt;? super T&gt; mapper) {
        return new CollectorImpl&lt;T, IntSummaryStatistics, IntSummaryStatistics&gt;(
                IntSummaryStatistics::new,
                (r, t) -&gt; r.accept(mapper.applyAsInt(t)),
                (l, r) -&gt; { l.combine(r); return l; }, CH_ID);
    }

    /**
     * Returns a {@code Collector} which applies an {@code long}-producing
     * mapping function to each input element, and returns summary statistics
     * for the resulting values.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper the mapping function to apply to each element
     * @return a {@code Collector} implementing the summary-statistics reduction
     *
     * @see #summarizingDouble(ToDoubleFunction)
     * @see #summarizingInt(ToIntFunction)
     */
    public static &lt;T&gt;
    Collector&lt;T, ?, LongSummaryStatistics&gt; summarizingLong(ToLongFunction&lt;? super T&gt; mapper) {
        return new CollectorImpl&lt;T, LongSummaryStatistics, LongSummaryStatistics&gt;(
                LongSummaryStatistics::new,
                (r, t) -&gt; r.accept(mapper.applyAsLong(t)),
                (l, r) -&gt; { l.combine(r); return l; }, CH_ID);
    }

    /**
     * Returns a {@code Collector} which applies an {@code double}-producing
     * mapping function to each input element, and returns summary statistics
     * for the resulting values.
     *
     * @param &lt;T&gt; the type of the input elements
     * @param mapper a mapping function to apply to each element
     * @return a {@code Collector} implementing the summary-statistics reduction
     *
     * @see #summarizingLong(ToLongFunction)
     * @see #summarizingInt(ToIntFunction)
     */
    public static &lt;T&gt;
    Collector&lt;T, ?, DoubleSummaryStatistics&gt; summarizingDouble(ToDoubleFunction&lt;? super T&gt; mapper) {
        return new CollectorImpl&lt;T, DoubleSummaryStatistics, DoubleSummaryStatistics&gt;(
                DoubleSummaryStatistics::new,
                (r, t) -&gt; r.accept(mapper.applyAsDouble(t)),
                (l, r) -&gt; { l.combine(r); return l; }, CH_ID);
    }

    /**
     * Implementation class used by partitioningBy.
     */
    private static final class Partition&lt;T&gt;
            extends AbstractMap&lt;Boolean, T&gt;
            implements Map&lt;Boolean, T&gt; {
        final T forTrue;
        final T forFalse;

        Partition(T forTrue, T forFalse) {
            this.forTrue = forTrue;
            this.forFalse = forFalse;
        }

        @Override
        public Set&lt;Map.Entry&lt;Boolean, T&gt;&gt; entrySet() {
            return new AbstractSet&lt;Map.Entry&lt;Boolean, T&gt;&gt;() {
                @Override
                public Iterator&lt;Map.Entry&lt;Boolean, T&gt;&gt; iterator() {
                    Map.Entry&lt;Boolean, T&gt; falseEntry = new SimpleImmutableEntry&lt;&gt;(false, forFalse);
                    Map.Entry&lt;Boolean, T&gt; trueEntry = new SimpleImmutableEntry&lt;&gt;(true, forTrue);
                    return Arrays.asList(falseEntry, trueEntry).iterator();
                }

                @Override
                public int size() {
                    return 2;
                }
            };
        }
    }
}
</pre>
</body>
</html>
